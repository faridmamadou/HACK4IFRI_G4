import streamlit as st
import pandas as pd
import numpy as np
import requests
import json
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go
import time

# Configuration de la page
st.set_page_config(
    page_title="Interface ML Model",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# URL de l'API
API_URL = "https://hack4ifrig4-production.up.railway.app/"  # Modifiez selon votre configuration

# Fonctions utilitaires
def api_request(endpoint, method="GET", data=None):
    """Effectue une requÃªte Ã  l'API"""
    url = f"{API_URL}/{endpoint}"
    try:
        if method == "GET":
            response = requests.get(url)
        elif method == "POST":
            response = requests.post(url, json=data)
        
        if response.status_code in [200, 201]:
            return response.json()
        else:
            st.error(f"Erreur API: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        st.error(f"Erreur lors de la connexion Ã  l'API: {str(e)}")
        return None

def check_api_health():
    """VÃ©rifie si l'API est accessible et si le modÃ¨le est chargÃ©"""
    try:
        health = api_request("health")
        if health and health.get("status") == "healthy":
            return True
        return False
    except:
        return False

def get_model_info():
    """RÃ©cupÃ¨re les informations sur le modÃ¨le"""
    return api_request("model-info")

def make_prediction(features):
    """Envoie une requÃªte de Classification Ã  l'API"""
    data = {"features": features}
    return api_request("predict", method="POST", data=data)

# Sidebar pour la navigation
st.sidebar.title("Navigation")
page = st.sidebar.radio(
    "SÃ©lectionnez une page",
    ["Accueil", "Classification", "Rapport du projet"]
)

# VÃ©rification de la connexion Ã  l'API
api_status = check_api_health()
model_info = get_model_info() if api_status else None

# Contenu de la page d'accueil
if page == "Accueil":
    st.title("Interface du ModÃ¨le de Machine Learning")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ## Bienvenue sur l'interface du modÃ¨le
        
        Cette application permet d'interagir avec un modÃ¨le de machine learning via une API FastAPI.
        
        ### FonctionnalitÃ©s disponibles:
        - ğŸ”® Faire des classifications en temps rÃ©el
        - ğŸ“Š Visualiser les rÃ©sultats
        - ğŸ“ Consulter le rapport du projet
        
        Utilisez la barre latÃ©rale pour naviguer entre les diffÃ©rentes pages.
        """)
    
    with col2:
        st.subheader("Ã‰tat du service")
        if api_status:
            st.success("âœ… API connectÃ©e")
            st.success("âœ… ModÃ¨le chargÃ©")
            if model_info:
                st.info(f"Type de modÃ¨le: {model_info.get('type', 'Non spÃ©cifiÃ©')}")
                st.info(f"Nombre de fonctionnalitÃ©s: {model_info.get('n_features', 'Non spÃ©cifiÃ©')}")
                if 'classes' in model_info:
                    st.info(f"Classes: {', '.join(map(str, model_info.get('classes', [])))}")
        else:
            st.error("âŒ API non connectÃ©e")
            st.warning("VÃ©rifiez que l'API FastAPI est en cours d'exÃ©cution.")
            st.code("uvicorn main:app --reload")
    
    st.markdown("---")
    
    st.subheader("Architecture du systÃ¨me")
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### Architecture Back-End (FastAPI)
        
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Client HTTP   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   API FastAPI   â”‚
        â”‚    (main.py)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ ModÃ¨le ML (pkl) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        """)
    
    with col2:
        st.markdown("""
        ### Architecture Front-End (Streamlit)
        
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  App Streamlit  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ RequÃªtes HTTP   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   API FastAPI   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        """)

# Page de Classification
elif page == "Classification":
    st.title("Classification avec le modÃ¨le")
    
    if not api_status:
        st.error("âŒ API non connectÃ©e. Impossible de faire des classifications.")
        st.stop()
    
    # RÃ©cupÃ©ration d'informations sur le modÃ¨le
    n_features = model_info.get('n_features', 4) if model_info else 4
    feature_names = model_info.get('features_expected', [f"Feature {i+1}" for i in range(n_features)]) if model_info else [f"Feature {i+1}" for i in range(n_features)]
    
    st.subheader("Entrez les caractÃ©ristiques")
    
    # MÃ©thode d'entrÃ©e
    input_method = st.radio(
        "MÃ©thode d'entrÃ©e des donnÃ©es",
        ["Formulaire", "CSV", "Exemple prÃ©dÃ©fini"]
    )
    
    features = []
    uploaded_df = None
    
    if input_method == "Formulaire":
        # CrÃ©ation d'un formulaire pour entrer les caractÃ©ristiques
        cols = st.columns(min(4, n_features))
        features = []
        
        for i in range(n_features):
            with cols[i % min(4, n_features)]:
                feat_value = st.number_input(
                    label=feature_names[i] if i < len(feature_names) else f"Feature {i+1}",
                    value=0.0,
                    format="%.2f",
                    key=f"feature_{i}"
                )
                features.append(feat_value)
        
        if st.button("PrÃ©dire", key="predict_form"):
            with st.spinner('Classification en cours...'):
                result = make_prediction(features)
                
                if result:
                    st.success("Classification rÃ©ussie!")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Classification", value=result.get('classe'))
                    
                    if result.get('probability') is not None:
                        with col2:
                            st.subheader("ProbabilitÃ©s")
                            probs = result.get('probability')
                            
                            if isinstance(probs, list):
                                if 'classes' in model_info:
                                    classes = model_info['classes']
                                    prob_df = pd.DataFrame({
                                        'Classe': [str(c) for c in classes],
                                        'ProbabilitÃ©': probs
                                    })
                                else:
                                    prob_df = pd.DataFrame({
                                        'Classe': [f"Classe {i}" for i in range(len(probs))],
                                        'ProbabilitÃ©': probs
                                    })
                                
                                fig = px.bar(prob_df, x='Classe', y='ProbabilitÃ©', title="ProbabilitÃ©s par classe")
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.write(f"ProbabilitÃ©: {probs}")
    
    elif input_method == "CSV":
        st.info("TÃ©lÃ©chargez un fichier CSV contenant les caractÃ©ristiques")
        uploaded_file = st.file_uploader("Choisissez un fichier CSV", type="csv")
        
        if uploaded_file is not None:
            try:
                uploaded_df = pd.read_csv(uploaded_file)
                st.write("AperÃ§u des donnÃ©es:")
                st.dataframe(uploaded_df.head())
                
                # VÃ©rification du nombre de colonnes
                if uploaded_df.shape[1] != n_features:
                    st.warning(f"Attention: Le modÃ¨le s'attend Ã  {n_features} caractÃ©ristiques, mais le CSV en contient {uploaded_df.shape[1]}.")
                
                if st.button("PrÃ©dire le premier exemple", key="predict_csv_first"):
                    with st.spinner('Classification en cours...'):
                        features = uploaded_df.iloc[0].values.tolist()
                        result = make_prediction(features)
                        
                        if result:
                            st.success("Classification rÃ©ussie!")
                            st.metric("Classification", value=result.get('prediction'))
                
                # Option pour prÃ©dire tous les exemples
                if st.button("PrÃ©dire tous les exemples", key="predict_csv_all"):
                    with st.spinner('Classifications en cours...'):
                        progress_bar = st.progress(0)
                        results = []
                        
                        # Limite Ã  100 exemples pour Ã©viter une surcharge
                        sample_size = min(100, len(uploaded_df))
                        sampled_df = uploaded_df.head(sample_size)
                        
                        for i, row in enumerate(sampled_df.itertuples()):
                            features = list(row)[1:]  # Exclure l'index
                            result = make_prediction(features)
                            if result:
                                results.append(result.get('prediction'))
                            else:
                                results.append(None)
                            progress_bar.progress((i + 1) / sample_size)
                            
                        # Affichage des rÃ©sultats
                        result_df = sampled_df.copy()
                        result_df['Classification'] = results
                        
                        st.success(f"{len(results)} Classifications effectuÃ©es!")
                        st.dataframe(result_df)
                        
                        # Visualisation des rÃ©sultats
                        if len(results) > 0 and all(r is not None for r in results):
                            st.subheader("Distribution des Classifications")
                            fig = px.histogram(result_df, x='Classification', title="Distribution des Classifications")
                            st.plotly_chart(fig, use_container_width=True)
            
            except Exception as e:
                st.error(f"Erreur lors du traitement du fichier CSV: {str(e)}")
    
    elif input_method == "Exemple prÃ©dÃ©fini":
        # Exemples prÃ©dÃ©finis (Ã  adapter selon votre modÃ¨le)
        example_sets = {
            "Exemple 1": [5.1, 3.5, 1.4, 0.2],
            "Exemple 2": [6.7, 3.1, 4.4, 1.4],
            "Exemple 3": [6.3, 2.8, 5.1, 1.5]
        }
        
        # Ajuster le nombre d'exemples en fonction du nombre de caractÃ©ristiques
        for key in list(example_sets.keys()):
            if len(example_sets[key]) != n_features:
                example_sets[key] = example_sets[key][:n_features] if len(example_sets[key]) > n_features else example_sets[key] + [0.0] * (n_features - len(example_sets[key]))
        
        selected_example = st.selectbox("SÃ©lectionnez un exemple", list(example_sets.keys()))
        
        features = example_sets[selected_example]
        
        # Affichage des caractÃ©ristiques de l'exemple
        example_df = pd.DataFrame([features], columns=feature_names[:n_features])
        st.dataframe(example_df)
        
        if st.button("Classer", key="predict_example"):
            with st.spinner('Classification en cours...'):
                result = make_prediction(features)
                
                if result:
                    st.success("Classification rÃ©ussie!")
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Classification", value=result.get('prediction'))
                    
                    if result.get('probability') is not None:
                        with col2:
                            st.subheader("ProbabilitÃ©s")
                            probs = result.get('probability')
                            
                            if isinstance(probs, list):
                                if 'classes' in model_info:
                                    classes = model_info['classes']
                                    prob_df = pd.DataFrame({
                                        'Classe': [str(c) for c in classes],
                                        'ProbabilitÃ©': probs
                                    })
                                else:
                                    prob_df = pd.DataFrame({
                                        'Classe': [f"Classe {i}" for i in range(len(probs))],
                                        'ProbabilitÃ©': probs
                                    })
                                
                                fig = px.bar(prob_df, x='Classe', y='ProbabilitÃ©', title="ProbabilitÃ©s par classe")
                                st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.write(f"ProbabilitÃ©: {probs}")

# Page du rapport
elif page == "Rapport du projet":
    st.title("Rapport du projet")
    
    # Sections du rapport
    st.sidebar.markdown("## Sections du rapport")
    report_section = st.sidebar.radio(
        "SÃ©lectionnez une section",
        ["Introduction", "PrÃ©processing", "ModÃ©lisation", "Ã‰valuation", "Conclusion"]
    )
    
    # Contenu de chaque section
    if report_section == "Introduction":
        st.header("Introduction")
        
        st.markdown("""
        ## Contexte du projet
        
        Ce projet vise Ã  dÃ©velopper un modÃ¨le de machine learning pour rÃ©soudre le problÃ¨me de [dÃ©crire le problÃ¨me].
        
        ### Objectifs
        
        - Objectif 1: Analyser les donnÃ©es disponibles
        - Objectif 2: DÃ©velopper un modÃ¨le prÃ©dictif performant
        - Objectif 3: DÃ©ployer le modÃ¨le via une API pour une utilisation en production
        
        ### DonnÃ©es utilisÃ©es
        
        Les donnÃ©es proviennent de [source des donnÃ©es] et contiennent [nombre] observations avec [nombre] caractÃ©ristiques.
        
        Le jeu de donnÃ©es comprend des informations sur [description des donnÃ©es].
        """)
        
        # Graphique fictif pour illustrer
        st.subheader("AperÃ§u des donnÃ©es")
        
        # CrÃ©er des donnÃ©es fictives pour dÃ©monstration
        np.random.seed(42)
        fake_data = pd.DataFrame({
            'Feature 1': np.random.normal(0, 1, 100),
            'Feature 2': np.random.normal(5, 2, 100),
            'Target': np.random.choice(['Class A', 'Class B', 'Class C'], 100)
        })
        
        fig = px.scatter(fake_data, x='Feature 1', y='Feature 2', color='Target', title="Visualisation des donnÃ©es")
        st.plotly_chart(fig, use_container_width=True)
    
    elif report_section == "PrÃ©processing":
        st.header("PrÃ©processing des donnÃ©es")
        
        st.markdown("""
        ## Ã‰tapes de prÃ©traitement
        
        Le prÃ©processing des donnÃ©es a impliquÃ© plusieurs Ã©tapes essentielles pour prÃ©parer les donnÃ©es Ã  l'entraÃ®nement du modÃ¨le:
        
        ### 1. Nettoyage des donnÃ©es
        
        - Gestion des valeurs manquantes
        - Suppression des doublons
        - Correction des erreurs et anomalies
        
        ### 2. Feature Engineering
        
        - CrÃ©ation de nouvelles caractÃ©ristiques
        - Transformation de variables existantes
        - Encodage des variables catÃ©gorielles
        
        ### 3. Normalisation et standardisation
        
        - Standardisation des caractÃ©ristiques numÃ©riques
        - Normalisation des distributions
        """)
        
        # Exemple de code pour le prÃ©processing
        st.subheader("Exemple de code de prÃ©processing")
        st.code("""
        # Chargement des donnÃ©es
        import pandas as pd
        from sklearn.preprocessing import StandardScaler, OneHotEncoder
        from sklearn.impute import SimpleImputer
        from sklearn.pipeline import Pipeline
        from sklearn.compose import ColumnTransformer
        
        # DÃ©finition des transformateurs
        numeric_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='median')),
            ('scaler', StandardScaler())
        ])
        
        categorical_transformer = Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ])
        
        # PrÃ©processeur combinÃ©
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', numeric_transformer, numeric_features),
                ('cat', categorical_transformer, categorical_features)
            ])
        
        # PrÃ©paration des donnÃ©es
        X_train_processed = preprocessor.fit_transform(X_train)
        """)
        
        # Visualisation du prÃ©processing
        st.subheader("Impact du prÃ©processing")
        
        # DonnÃ©es fictives pour dÃ©monstration
        np.random.seed(42)
        before_data = pd.DataFrame({
            'Feature': np.random.normal(0, 2, 100)
        })
        
        after_data = pd.DataFrame({
            'Feature': (before_data['Feature'] - before_data['Feature'].mean()) / before_data['Feature'].std()
        })
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig1 = px.histogram(before_data, x='Feature', title="Avant standardisation")
            st.plotly_chart(fig1, use_container_width=True)
        
        with col2:
            fig2 = px.histogram(after_data, x='Feature', title="AprÃ¨s standardisation")
            st.plotly_chart(fig2, use_container_width=True)
    
    elif report_section == "ModÃ©lisation":
        st.header("ModÃ©lisation")
        
        st.markdown("""
        ## Approche de modÃ©lisation
        
        ### ModÃ¨les Ã©valuÃ©s
        
        Nous avons testÃ© plusieurs modÃ¨les pour rÃ©soudre ce problÃ¨me:
        
        1. **Random Forest**: Un ensemble d'arbres de dÃ©cision qui amÃ©liore la prÃ©cision et rÃ©duit le surapprentissage
        2. **Gradient Boosting**: Une mÃ©thode d'ensemble qui construit progressivement des modÃ¨les
        3. **Support Vector Machine**: Efficace pour les problÃ¨mes Ã  haute dimension
        4. **Neural Network**: Un rÃ©seau de neurones multicouche pour capturer des relations complexes
        
        ### MÃ©thodologie d'entraÃ®nement
        
        - Validation croisÃ©e Ã  k-plis (k=5)
        - Recherche d'hyperparamÃ¨tres via GridSearchCV
        - Ã‰chantillonnage stratifiÃ© pour gÃ©rer les dÃ©sÃ©quilibres de classe
        """)
        
        # Visualisation de la performance des modÃ¨les
        st.subheader("Comparaison des modÃ¨les")
        
        # DonnÃ©es fictives pour dÃ©monstration
        model_data = pd.DataFrame({
            'ModÃ¨le': ['Random Forest', 'Gradient Boosting', 'SVM', 'Neural Network'],
            'PrÃ©cision': [0.92, 0.94, 0.88, 0.91],
            'Rappel': [0.90, 0.92, 0.85, 0.89],
            'F1-Score': [0.91, 0.93, 0.86, 0.90]
        })
        
        fig = go.Figure()
        
        fig.add_trace(go.Bar(
            x=model_data['ModÃ¨le'],
            y=model_data['PrÃ©cision'],
            name='PrÃ©cision',
            marker_color='royalblue'
        ))
        
        fig.add_trace(go.Bar(
            x=model_data['ModÃ¨le'],
            y=model_data['Rappel'],
            name='Rappel',
            marker_color='indianred'
        ))
        
        fig.add_trace(go.Bar(
            x=model_data['ModÃ¨le'],
            y=model_data['F1-Score'],
            name='F1-Score',
            marker_color='green'
        ))
        
        fig.update_layout(
            title='Performance des diffÃ©rents modÃ¨les',
            xaxis_title='ModÃ¨le',
            yaxis_title='Score',
            barmode='group',
            yaxis=dict(range=[0.8, 1])
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Code d'entraÃ®nement
        st.subheader("Exemple de code d'entraÃ®nement")
        st.code("""
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.model_selection import GridSearchCV, cross_val_score
        
        # DÃ©finition du modÃ¨le
        rf = RandomForestClassifier(random_state=42)
        
        # HyperparamÃ¨tres Ã  tester
        param_grid = {
            'n_estimators': [100, 200, 300],
            'max_depth': [None, 10, 20, 30],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        # Recherche d'hyperparamÃ¨tres
        grid_search = GridSearchCV(
            estimator=rf,
            param_grid=param_grid,
            cv=5,
            scoring='accuracy',
            n_jobs=-1
        )
        
        # EntraÃ®nement
        grid_search.fit(X_train, y_train)
        
        # Meilleur modÃ¨le
        best_model = grid_search.best_estimator_
        
        # Enregistrement du modÃ¨le
        import joblib
        joblib.dump(best_model, 'model.pkl')
        """)
    
    elif report_section == "Ã‰valuation":
        st.header("Ã‰valuation du modÃ¨le")
        
        st.markdown("""
        ## RÃ©sultats de l'Ã©valuation
        
        ### MÃ©triques de performance
        
        Notre modÃ¨le final a Ã©tÃ© Ã©valuÃ© sur un ensemble de test indÃ©pendant avec les rÃ©sultats suivants:
        
        - **PrÃ©cision**: 0.94
        - **Rappel**: 0.92
        - **F1-Score**: 0.93
        - **AUC-ROC**: 0.97
        
        ### Analyse des erreurs
        
        Une analyse des erreurs a rÃ©vÃ©lÃ© que le modÃ¨le avait tendance Ã  confondre certaines classes dans des cas spÃ©cifiques.
        """)
        
        # Matrice de confusion
        st.subheader("Matrice de confusion")
        
        # DonnÃ©es fictives pour dÃ©monstration
        cm = np.array([
            [45, 3, 2],
            [1, 50, 4],
            [2, 3, 40]
        ])
        
        classes = ['Classe A', 'Classe B', 'Classe C']
        
        fig = px.imshow(
            cm,
            x=classes,
            y=classes,
            color_continuous_scale='Blues',
            labels=dict(x="Classification", y="RÃ©alitÃ©", color="Nombre")
        )
        
        fig.update_layout(
            title='Matrice de confusion',
            xaxis_title='Classe prÃ©dite',
            yaxis_title='Classe rÃ©elle'
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Courbe ROC
        st.subheader("Courbe ROC")
        
        # DonnÃ©es fictives pour la courbe ROC
        fpr = np.linspace(0, 1, 100)
        tpr = 1 - np.exp(-5 * fpr)
        
        fig = px.line(
            x=fpr, y=tpr,
            labels={'x': 'Taux de faux positifs', 'y': 'Taux de vrais positifs'},
            title='Courbe ROC'
        )
        
        fig.add_shape(
            type='line',
            line=dict(dash='dash', width=1),
            x0=0, x1=1, y0=0, y1=1
        )
        
        fig.update_layout(
            xaxis_range=[0, 1],
            yaxis_range=[0, 1]
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Feature importance
        st.subheader("Importance des caractÃ©ristiques")
        
        # DonnÃ©es fictives pour l'importance des caractÃ©ristiques
        feature_importance = pd.DataFrame({
            'Feature': ['Feature 1', 'Feature 2', 'Feature 3', 'Feature 4', 'Feature 5'],
            'Importance': [0.35, 0.25, 0.20, 0.15, 0.05]
        }).sort_values('Importance', ascending=False)
        
        fig = px.bar(
            feature_importance,
            x='Importance',
            y='Feature',
            orientation='h',
            title='Importance des caractÃ©ristiques'
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    elif report_section == "Conclusion":
        st.header("Conclusion et perspectives")
        
        st.markdown("""
        ## Conclusion
        
        Ce projet nous a permis de dÃ©velopper un modÃ¨le de machine learning performant pour [dÃ©crire le problÃ¨me]. 
        
        Nous avons obtenu d'excellents rÃ©sultats avec un modÃ¨le de Gradient Boosting, atteignant une prÃ©cision de 94% sur l'ensemble de test.
        
        ### Principaux apprentissages
        
        1. L'importance du prÃ©processing des donnÃ©es pour obtenir des performances optimales
        2. L'efficacitÃ© des mÃ©thodes d'ensemble pour ce type de problÃ¨me
        3. La nÃ©cessitÃ© d'une validation croisÃ©e rigoureuse pour Ã©viter le surapprentissage
        
        ## Perspectives
        
        Pour amÃ©liorer davantage le modÃ¨le, nous pourrions:
        
        - Collecter davantage de donnÃ©es pour les classes minoritaires
        - Explorer des architectures de deep learning plus complexes
        - IntÃ©grer des donnÃ©es externes supplÃ©mentaires
        - Mettre en place un systÃ¨me de monitoring pour dÃ©tecter la dÃ©rive conceptuelle
        
        ## DÃ©ploiement
        
        Le modÃ¨le a Ã©tÃ© dÃ©ployÃ© avec succÃ¨s via une API FastAPI, permettant son intÃ©gration facile dans diffÃ©rentes applications.
        """)
        
        # Visualisation du workflow complet
        st.subheader("Workflow complet du projet")
        
        workflow_code = """
        graph TD
          A[Collecte de donnÃ©es] --> B[PrÃ©processing]
          B --> C[Feature Engineering]
          C --> D[EntraÃ®nement du modÃ¨le]
          D --> E[Ã‰valuation]
          E --> F[DÃ©ploiement API]
          F --> G[Interface utilisateur]
          E --> H{Performance suffisante?}
          H -->|Non| B
          H -->|Oui| F
        """
        
        st.graphviz_chart(workflow_code)
        
        # Calendrier du projet
        st.subheader("Calendrier du projet")
        
        project_timeline = pd.DataFrame({
            'TÃ¢che': ['Collecte de donnÃ©es', 'PrÃ©processing', 'ModÃ©lisation', 'Ã‰valuation', 'DÃ©ploiement'],
            'DÃ©but': pd.to_datetime(['2023-01-01', '2023-01-15', '2023-02-01', '2023-02-15', '2023-03-01']),
            'Fin': pd.to_datetime(['2023-01-15', '2023-01-31', '2023-02-15', '2023-02-28', '2023-03-15'])
        })
        
        fig = px.timeline(
            project_timeline, 
            x_start='DÃ©but', 
            x_end='Fin', 
            y='TÃ¢che',
            title='Calendrier du projet'
        )
        
        fig.update_layout(
            xaxis_title='Date',
            yaxis_title='TÃ¢che'
        )
        
        st.plotly_chart(fig, use_container_width=True)

# Footer
st.markdown("---")
st.markdown("DÃ©veloppÃ© pour le HACK4IFRFI par le Groupe 4")